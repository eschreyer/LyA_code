import numpy as np
from astropy import constants as const
from astropy import table
from scipy.interpolate import interp1d
from matplotlib import pyplot as plt # for debugging

# region utility functions
def v2w(velocities, wrest):
    """

    Parameters
    ----------
    velocities : km s-1

    Returns
    -------

    """
    c = const.c.to_value('km s-1')
    return (1 + np.asarray(velocities)/c) * wrest


def w2v(wavelengths, wrest):
    """

    Parameters
    ----------
    velocities : km s-1

    Returns
    -------

    """
    c = const.c.to_value('km s-1')
    return (np.asarray(wavelengths)/wrest - 1)*c


def midpts(x):
    return (x[1:] + x[:-1])/2.


def cumtrapz(y, x):
    areas = midpts(y) * np.diff(x)
    result = np.cumsum(areas)
    result = np.insert(result, 0, 0)
    return result


def bin(x_edges, x, y):
    integral = cumtrapz(y, x)
    Iedges = np.interp(x_edges, x, integral)
    return np.diff(Iedges)


def ensure_2d(x):
    if x.ndim == 1:
        return x[None,:]
    elif x.ndim == 2:
        return x
    else:
        ValueError


def rebin(new_edges, old_edges, y):
    dx = np.diff(old_edges)
    areas = y*dx
    integral = np.insert(np.cumsum(areas), 0, 0)
    Iedges = np.interp(new_edges, old_edges, integral)
    return np.diff(Iedges)/np.diff(new_edges)


def rebin_list(new_edges, old_edges_list, y_list):
    y_new = [rebin(new_edges, old_edges_list[i], y_list[i]) for i in range(len(y_list))]
    return np.array(y_new)


def rebin_error(new_edges, old_edges, err):
    dx = np.diff(old_edges)
    E = err*dx
    V = E**2
    integral = np.insert(np.cumsum(V), 0, 0)
    Iedges = np.interp(new_edges, old_edges, integral)
    Vnew = np.diff(Iedges)
    return np.sqrt(Vnew) / np.diff(new_edges)


def cumtrapz_griddata(y, x):
    areas = midpts(y) * np.diff(x)[:, None]
    result = np.cumsum(areas, axis=0)
    result = np.vstack((np.zeros_like(result[0]),
                        result))
    return result


def bin_integrate(x_bin_edges, xin, yin):
    I = cumtrapz(yin, xin)
    Iedges = np.interp(x_bin_edges, xin, I)
    Ibin = np.diff(Iedges)
    return Ibin


def epoch_averages(dt, f, epoch_masks):
    avgs = []
    for mask in epoch_masks:
        Fout_avg = np.sum(f[mask] * dt[mask]) / np.sum(dt[mask])
        avgs.append(Fout_avg)
    return np.array(avgs)

# endregion


class FitPackage(object):
    def __init__(self, wgrid, tgrid, spectrograph, data, line_profile, wrest=1215.67, epoch_divisions=None):
        """

        Parameters
        ----------
        wgrid : wavelength grid of model in AA
        tgrid : time grid of model in *hours*
        spectrograph : Spectrograph object representing the instrument that collected the data
        data : astropy table generated by the stis_reduce module that contains transit spectra
        line_profile : astropy table generated by the lya module that contains the unabsorbed line profile
        wrest : rest wavelength for the line in AA
        epoch_divisions: JD time marking a division between the epochs. will be used to separately scale
            fluxes for each epoch.

        Returns
        -------
        oot_profile, oot_data, transit_data, simulate_spectra, get_lightcurves, compute_chi2
        """

        if np.any(data['pha'] < tgrid[0]) | np.any(data['phb'] > tgrid[-1]):
            raise ValueError("Time grid does not cover all of the data.")
        we = np.array(data['we'])
        dw = np.mean(np.diff(data['we'], axis=1))
        npix_buffer = 85
        w_buffer = npix_buffer*dw
        if np.any(we[:,0] - w_buffer < wgrid[0]) | np.any(we[:,-1] + w_buffer > wgrid[-1]):
            y_endpt_max = np.max(line_profile['y'][[0,-1]])
            y_max = np.max(line_profile['y'])
            if y_endpt_max > y_max / 1000.:
                raise ValueError("Wavelength grid does not extend at least {:.2f} Ã… beyond the data "
                                 "and the line profile is not negligible at the edges of the grid."
                                 "This could lead to inaccuracies."
                                 "Extend wavelength grid accordingly."
                                 "".format(w_buffer))
        self.wgrid = wgrid
        self.tgrid = tgrid
        self.spectrograph = spectrograph
        self.wrest = wrest

        line_profile = line_profile.copy()
        self.line_profile = line_profile
        self.line_profile_on_grid = np.interp(wgrid, line_profile['w'], line_profile['y'])
        self.line_flux = np.trapz(self.line_profile_on_grid, wgrid)

        data = data.copy() # avoids modifying the input tables
        self.Ndata = len(data)
        self.data = data
        data.sort('ph')
        data['dt'] = (data['phb'] - data['pha'])

        # create functions to simulate observation of a model spectrum
        observe_functions, Fouts = [], []
        for row in data:
            w, ap = row['w'], row['aperture']
            obsfun = spectrograph.fast_observe_function(w, wgrid, ap)
            observe_functions.append(obsfun)
        data['obsfun'] = observe_functions

        # make masks to speed up application of epoch-by-epoch scaling factors to line profile
        self.epoch_divisions = epoch_divisions
        if epoch_divisions is None:
            self.Nepochs = 1
            self.epoch_masks = [np.ones(self.Ndata, bool)]
        else:
            self.Nepochs = len(epoch_divisions) + 1
            isort = np.searchsorted(epoch_divisions, data['t'])
            masks = []
            for iepoch in range(self.Nepochs):
                masks.append(iepoch == isort)
            self.epoch_masks = masks


    def __getattr__(self, item):
        if item in {'__getstate__', '__setstate__'}:
            return object.__getattr__(self, item)
        elif item in self.data.colnames:
            return self.data[item]
        else:
            raise AttributeError("FitPackage object has not {} attribute nor is it a column in the object's data table"
                                 "".format(item))


    def scalefacs2vec(self, scalefacs):
        # expand normalization factors into a vector so there is one factor for each data point
        if len(scalefacs) != self.Nepochs:
            raise ValueError('Number of scalefacs must equal number of epochs specified '
                             'when initiliazing the fitpackage object.')
        scalevec = np.ones(self.Ndata)
        for mask, fac in zip(self.epoch_masks, scalefacs):
            scalevec[mask] = fac
        return scalevec


    def average_depths(self, depths):
        # average depths over the observations times
        integral_depth = cumtrapz_griddata(depths, self.tgrid)
        interp = interp1d(self.tgrid, integral_depth, axis=0)
        data = self.data
        avg_depth = (interp(data['phb']) - interp(data['pha'])) / data['dt'][:, None]
        return avg_depth


    def simulate_spectra(self, depths, scalefacs):
        """

        Parameters
        ----------
        depths : array of transit depth on [time, wavelength] axes

        Returns
        -------
        simdata
        """
        data = self.data
        scalevec = self.scalefacs2vec(scalefacs)
        avg_depth = self.average_depths(depths)

        # multiply by OOT profile to get transit-absorbed profiles
        absorbed_profiles = (1 - avg_depth) * self.line_profile_on_grid[None, :] * scalevec[:,None]

        # simulate observation of the absorbed profiles
        sim_data = []
        for obs, profile in zip(data, absorbed_profiles):
            observe = obs['obsfun']
            spec = observe(profile)
            sim_data.append(spec)
        sim_data = np.array(sim_data)

        return sim_data


    def get_lightcurves(self, depths, bin_edges, scalefacs):
        """

        Parameters
        ----------
        depths
        bin_edges : km s-1

        Returns
        -------
        t, dt, data_lc, data_lc_err, sim_lc, oot_fluxes
        """
        bin_edges_w = v2w(bin_edges, self.wrest)

        sim_data = self.simulate_spectra(depths, scalefacs)

        # for out of transit fluxes (these will vary by aperture and binning, hence the need to compute)
        depths_notransit = np.zeros_like(depths)
        sim_oot = self.simulate_spectra(depths_notransit, scalefacs)

        # rebin observed and simulated spectra and errors to the lightcurve ranges
        data_lc = []
        data_lc_err = []
        sim_lc = []
        oot_norms = []
        for obs, sim, oot in zip(self.data, sim_data, sim_oot):
            we = obs['we']
            data_fluxes = rebin(bin_edges_w, we, obs['f'])
            data_err = rebin_error(bin_edges_w, we, obs['e'])
            sim_fluxes = rebin(bin_edges_w, we, sim)
            oot_fluxes = rebin(bin_edges_w, we, oot)
            data_lc.append(data_fluxes)
            data_lc_err.append(data_err)
            sim_lc.append(sim_fluxes)
            oot_norms.append(oot_fluxes)
        data_lc, data_lc_err, sim_lc, oot_norms = map(np.asarray, (data_lc, data_lc_err, sim_lc, oot_norms))

        return data_lc, data_lc_err, sim_lc, oot_norms


    def get_lightcurve_no_lsf(self, depths, bin_edges, scalefacs):
        # computes the line flux in the given bins without processing through the intrument LSF
        # this will be faster but introduce some error if using on a portion of a resolved line
        # if the line is unresolved (e.g., G140L data), it could be very inaccurate for bins covering part of the line
        # In either case, it will be accurate if the entire line is integrated (i.e., the input is a single bin
        # covering the entire line)

        bin_edges_w = v2w(bin_edges, self.wrest)
        dw = np.diff(bin_edges_w)
        avg_depth = self.average_depths(depths)
        scalevec = self.scalefacs2vec(scalefacs)

        # multiply by OOT profile to get transit-absorbed profiles
        absorbed_profiles = (1 - avg_depth) * self.line_profile_on_grid[None, :] * scalevec[:, None]

        # multiply by OOT profile to get transit-absorbed profiles
        data_lc, data_lc_err, sim_lc = [], [], []
        for obs, sim in zip(self.data, absorbed_profiles):
            Fdata = rebin(bin_edges_w, obs['we'], obs['f'])*dw
            Edata = rebin_error(bin_edges_w, obs['we'], obs['e'])*dw
            Fsim = bin_integrate(bin_edges_w, self.wgrid, sim)
            data_lc.append(Fdata)
            data_lc_err.append(Edata)
            sim_lc.append(Fsim)
        data_lc, data_lc_err, sim_lc = map(np.array, (data_lc, data_lc_err, sim_lc))

        return data_lc, data_lc_err, sim_lc


    def get_lightcurve_full_band(self, depths, scalefacs):
        bin_edges = w2v(self.wgrid[[0,-1]], self.wrest)
        data_lc, data_lc_err, sim_lc = self.get_lightcurve_no_lsf(depths, bin_edges, scalefacs)
        data_lc, data_lc_err, sim_lc = data_lc[:,0], data_lc_err[:,0], sim_lc[:,0]
        return data_lc, data_lc_err, sim_lc

    def compute_chi2_with_full_band_lightcurve(self, depths, scalefacs):
        data_lc, data_lc_err, sim_lc = self.get_lightcurve_full_band(depths, scalefacs)
        terms = (data_lc - sim_lc)**2/data_lc_err**2
        return np.sum(terms)

    def compute_logL_with_full_band_lightcurve(self, depths, scalefacs):
        data_lc, data_lc_err, sim_lc = self.get_lightcurve_full_band(depths, scalefacs)
        terms = terms = -(1/2) * ((data_lc - sim_lc)**2/data_lc_err**2 + np.log(2 * np.pi * data_lc_err**2))
        return np.sum(terms)

    def compute_chi2_with_partial_band_lightcurve(self, depths, band, scalefacs):
        data_lc, data_lc_err, sim_lc, oot_norms = self.get_lightcurves(depths, band, scalefacs)
        terms = (sim_lc - data_lc)**2/data_lc_err**2
        return np.sum(terms)

    def compute_logL_with_partial_band_lightcurve(self, depths, band, scalefacs):
        data_lc, data_lc_err, sim_lc, oot_norms = self.get_lightcurves(depths, band, scalefacs)
        terms = -(1/2) * ((data_lc - sim_lc)**2/data_lc_err**2 + np.log(2 * np.pi * data_lc_err**2))
        return np.sum(terms)

    def SuperSampler(self):
        # create a fitpackage object with a dummy dataset to use for making lightcurves with time sampling matching
        # tgrid instead of the times of the data points
        n = len(self.tgrid)
        data = self.data
        names = data.colnames
        cols = {}
        for name in names:
            oldcol = data[name]
            shape = list(oldcol.shape)
            shape[0] = n
            newcol = np.zeros(shape, dtype=oldcol.dtype)
            cols[name] = newcol
        dummydata = table.Table(cols)

        # code averages model across time bins, so I need to make fake tiny time bins
        # cloogy, but I think better than duplicating all of this class to make functions that don't bin
        dt_min = np.min(np.diff(self.tgrid))
        dummydata['ph'] = self.tgrid
        dummydata['pha'] = self.tgrid - dt_min/1e5
        dummydata['pha'][0] = self.tgrid[0] # lest the function try to interpolate beyond the grid and throw an error
        dummydata['phb'] = self.tgrid + dt_min/1e5
        dummydata['phb'][-1] = self.tgrid[-1]
        dummydata['t'] = dummydata['ph']/24
        dummydata['ta'] = dummydata['pha']/24
        dummydata['tb'] = dummydata['phb']/24

        m = len(dummydata['w'][0])
        dummydata['we'] = np.tile(data['we'][0], (n,1))
        dummydata['w'] = np.tile(data['w'][0], (n,1))
        dummydata['f'] = np.ones((n,m))
        dummydata['e'] = np.ones((n,m))
        dummydata['bs'] = np.zeros((n,m), bool)
        dummydata['bkgnd'] = np.zeros((n,m))
        dummydata['fluxfac'] = np.ones((n,m))
        dummydata['root'] = 'dummy data'

        _, i, cts = np.unique(data['aperture'], return_index=True, return_counts=True)
        imode = i[np.argmax(cts)]
        ap = data['aperture'][imode]
        dummydata['aperture'] = ap

        return FitPackage(self.wgrid, self.tgrid, self.spectrograph, dummydata,
                          self.line_profile, wrest=self.wrest, epoch_divisions=self.epoch_divisions)
